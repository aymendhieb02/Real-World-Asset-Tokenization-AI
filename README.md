# Real Estate Price Prediction and Investment Recommendation System

> **Part of [Real-World Asset Tokenization AI Platform](https://github.com/aymendhieb02/Real-World-Asset-Tokenization-AI)**  
> This branch (`Models_AI`) contains the AI/ML models for property price prediction, forecasting, and investment recommendations.

## ðŸŽ¯ Overview

This module provides the AI-powered backend for the Real-World Asset Tokenization platform, enabling:
- **Instant Property Valuation** with 83.92% accuracy (RÂ² = 0.8392)
- **10-Year Price Forecasting** for investment planning
- **Intelligent Investment Recommendations** based on ROI and risk analysis
- **Geographic Clustering** for location-based market insights

For the complete platform including frontend and blockchain integration, see the [main repository](https://github.com/aymendhieb02/Real-World-Asset-Tokenization-AI).

---

## 1. Abstract

This project presents a comprehensive machine learning solution for real estate price prediction and investment analysis. The system addresses the critical challenge of accurately estimating property values and identifying profitable investment opportunities in the real estate market. 

**Problem Statement:** Real estate investment decisions require accurate price predictions, future value forecasting, and risk assessment. Traditional methods often fail to capture complex relationships between property features, location, and market trends, leading to suboptimal investment decisions.

**Solution:** We developed an end-to-end pipeline that combines advanced data preprocessing techniques with XGBoost regression models to predict property prices. The system includes sophisticated imputation strategies for handling missing data, outlier detection and treatment, feature engineering, and time-based forecasting capabilities. Additionally, we implemented a geographic clustering system using MiniBatchKMeans to identify spatial patterns and an investment recommendation engine that evaluates properties based on predicted ROI and risk metrics.

**Key Results:**
- Achieved **RÂ² score of 0.8392** on test data, explaining 83.92% of price variance
- Mean Absolute Error (MAE) of **$101,759** and Mean Absolute Percentage Error (MAPE) of **25.46%**
- Successfully processed and cleaned **2.2+ million property records**
- Implemented time-based forecasting for 1, 5, and 10-year price predictions
- Created an investment recommendation system with risk-adjusted ROI calculations
- Achieved **0.4768 silhouette score** for geographic clustering with 30 clusters

---

## 2. Methodology

### 2.1 Data

#### Data Sources
- **Primary Dataset:** Realtor.com property dataset (`realtor-data.zip.csv`)
  - Contains property listings with features such as price, bedrooms, bathrooms, lot size, location, and sale history
  - Initial dataset size: **2,224,841 rows** with 12 columns
- **Geographic Data:** ZIP code latitude/longitude mapping (`zip_latlng.csv`)
  - Used for geographic clustering and location-based feature engineering

#### Data Format and Size
- **Format:** CSV files
- **Initial Size:** 2,224,841 properties
- **Final Cleaned Dataset:** 2,224,561 properties (after removing invalid prices)
- **Features:** 12 original columns + 20 engineered features

#### Data Preprocessing and Cleaning

**Missing Value Analysis:**
- `house_size`: 567,874 missing (25.5%)
- `prev_sold_date`: 733,256 missing (33.0%)
- `bed`: 481,317 missing (21.6%)
- `bath`: 511,771 missing (23.0%)
- `acre_lot`: 325,589 missing (14.6%)
- `street`: 10,866 missing (0.5%)
- `city`: 1,407 missing (0.06%)
- `state`: 8 missing (<0.001%)
- `zip_code`: 299 missing (0.01%)
- `brokered_by`: 4,533 missing (0.2%)

**Preprocessing Steps:**

1. **Price Cleaning:**
   - Removed rows with missing prices (1,541 rows)
   - Filtered invalid prices: removed properties with price â‰¤ $1,000 or > $10,000,000

2. **Smart Imputation for Bedrooms and Bathrooms:**
   - Implemented hierarchical imputation using grouped medians
   - Created price and lot size bins for context-aware imputation
   - Used house size as primary predictor when available
   - Applied cascade approach: group by (size_bin, price_bin, city, state) â†’ (size_bin, price_bin, state) â†’ (size_bin, price_bin) â†’ fallback to state median â†’ overall median
   - For bathrooms: used bedroom-to-bathroom ratio (0.75) as fallback

3. **Acre Lot Imputation:**
   - Hierarchical imputation with time limit (30 seconds)
   - Grouped by state, city, price decile, and size quartile
   - Applied linear interpolation for remaining values
   - Added realistic variation based on property characteristics (urban vs rural)

4. **Street Address Imputation:**
   - Pattern-based generation using ZIP code and price segments
   - Extracted street type patterns from existing addresses
   - Generated realistic addresses based on price tier

5. **City and ZIP Code Imputation:**
   - Created bidirectional mapping (ZIP â†’ City, City â†’ ZIP)
   - Filled missing values using location relationships
   - Used placeholders for remaining missing values

6. **Broker Imputation:**
   - Built location-based broker database
   - Weighted random selection based on broker frequency in area
   - Fallback to state-level popular brokers
   - Price-tier-based default brokers for remaining cases

7. **House Size Imputation (XGBoost-based):**
   - Trained XGBoost model on 1,656,967 known samples
   - Features: price, bed, bath, acre_lot, location codes, price categories
   - Applied constraints: bedroom-based size limits (300-800 sqft per bedroom)
   - Price per sqft validation ($50-$500 range)
   - Lot size constraints (house size â‰¤ 60% of lot size)
   - Final range: 500-10,000 sqft

8. **Previous Sale Date Imputation:**
   - ML-based imputation using XGBoost
   - Converted dates to days since 2000
   - Features: price, property characteristics, location, time features
   - Applied temporal constraints (1990-2024 range)
   - Generated seasonal features (month, quarter, season)

9. **Outlier Treatment:**
   - **Price:** Log-transformation + Z-score filtering (Z > 4), capped at 0.1% and 99.9% percentiles
   - **House Size:** Physical constraints (200-50,000 sqft), capped at 0.1% and 99.9% percentiles
   - **Price per Sqft:** Cross-validation check ($30-$800/sqft), flagged for review
   - **Bedrooms:** 0-12 range, capped at 1st and 99th percentiles
   - **Bathrooms:** 1-8 range, capped at 1st and 99th percentiles
   - **Lot Size:** 0.05-20 acres, capped at 0.1% and 99.5% percentiles

**Final Dataset Quality:**
- Zero missing values in critical columns (price, bed, bath, house_size, acre_lot)
- All properties have complete location information
- Outliers treated while preserving data distribution

---

### 2.2 Approach / Algorithms

#### Models Used

1. **XGBoost Regressor (Primary Model)**
   - **Purpose:** Property price prediction
   - **Algorithm:** Gradient Boosting Decision Trees
   - **Why XGBoost:**
     - Handles non-linear relationships effectively
     - Robust to outliers and missing values
     - Provides feature importance rankings
     - Excellent performance on tabular data

2. **PropertyPriceForecaster (10-Year Forecasting Model)**
   - **Purpose:** Predict property prices for 1, 5, and 10 years into the future
   - **Algorithm:** Hybrid approach combining XGBoost predictions with historical growth trends
   - **Key Components:**
     - **Base Model:** XGBoost regressor trained on temporal features
     - **Growth Rate Calculation:** Year-over-year median price changes by ZIP code
     - **Inflation Adjustment:** 2.5% annual inflation rate
     - **Blending Strategy:** 70% ML prediction + 30% trend-based growth
   - **How It Works:**
     1. Calculates historical growth rates for each ZIP code from past sales data
     2. Predicts current price using XGBoost model with temporal features
     3. For each future year (1, 5, 10), generates two predictions:
        - **ML Prediction:** XGBoost model with adjusted temporal features for target year
        - **Trend Prediction:** Compound growth based on historical growth rate + inflation
     4. Blends both predictions (70% ML, 30% trend) for robust forecasts
     5. Applies growth rate bounds (2-8% annually) to prevent unrealistic projections
   - **Output:** Current price, 1-year, 5-year, and 10-year price forecasts with growth rate

3. **RealEstateInvestmentAdvisor (ROI Recommendation System)**
   - **Purpose:** Identify top investment opportunities based on budget, ROI, and risk
   - **Algorithm:** Multi-step filtering and ranking system
   - **Key Components:**
     - **Property Filtering:** Budget, location (state/city), bedrooms, bathrooms
     - **Price Forecasting:** Uses forecasting model to predict 1, 5, and 10-year prices
     - **ROI Calculation:** Return on Investment for each time horizon
     - **Risk Assessment:** Price volatility (coefficient of variation) by ZIP code
     - **Ranking:** Sorted by 10-year ROI, with risk-adjusted ROI metric
   - **How It Works:**
     1. **Filtering Phase:**
        - Filters properties by user-specified budget
        - Applies optional filters: state, city, min/max bedrooms, min bathrooms
        - Samples up to 5,000 properties for analysis (performance optimization)
     
     2. **Forecasting Phase:**
        - For each property, forecasts prices at 1, 5, and 10 years
        - Uses the PropertyPriceForecaster model with property-specific features
        - Adjusts temporal features (years_since_2000, decade, etc.) for each horizon
     
     3. **ROI Calculation:**
        - Calculates ROI for each time horizon: `ROI = (Future_Price - Current_Price) / Current_Price Ã— 100`
        - Provides ROI metrics: `roi_1_year`, `roi_5_year`, `roi_10_year`
     
     4. **Risk Assessment:**
        - Computes price volatility for each ZIP code: `Risk = std(price) / mean(price)`
        - Higher risk indicates more price variability in the area
        - Default risk of 0.10 (10%) for ZIP codes with insufficient data (<5 properties)
     
     5. **Ranking and Selection:**
        - Sorts properties by `roi_10_year` (descending)
        - Calculates risk-adjusted ROI: `risk_adjusted_roi = roi_10_year / (1 + risk)`
        - Returns top N recommendations (default: 10)
     
     6. **Output Format:**
        - Returns dictionary with success status, property data, and metadata
        - Each property includes: location, features, current price, forecasted prices, ROI metrics, risk, and risk-adjusted ROI
   - **Use Case:** Investment decision support for real estate investors with specific budget and criteria

4. **DBSCAN Street-Level Clustering**
   - **Purpose:** Geographic clustering of properties within streets
   - **Algorithm:** Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
   - **Why DBSCAN:**
     - Identifies clusters of nearby houses on the same street
     - Handles irregular cluster shapes (not just circular)
     - Automatically identifies noise points (isolated properties)
     - No need to pre-specify number of clusters
   - **Configuration:**
     - **Radius (eps):** 50 meters (0.05 km) - houses within this distance are grouped
     - **Min Samples:** 2 houses minimum to form a cluster
     - **Strategy:** Clusters houses within each street separately, then assigns global cluster IDs
   - **Output:** Creates `street_cluster` and `within_street_cluster` columns for geographic analysis

5. **MiniBatchKMeans Clustering (Alternative Approach)**
   - **Purpose:** Fast geographic clustering of all properties (alternative to DBSCAN)
   - **Algorithm:** Mini-batch K-Means clustering
   - **Why MiniBatchKMeans:**
     - 10-100x faster than standard K-Means for large datasets
     - Handles 2.2M+ data points efficiently
     - Memory-efficient batch processing
   - **Configuration:** 30 clusters for balanced granularity and performance

#### Key Design Decisions

**Hyperparameter Optimization:**
- **Method:** Optuna framework with 30 trials
- **Search Space:**
  - `n_estimators`: 300-900
  - `learning_rate`: 0.01-0.15
  - `max_depth`: 3-10
  - `min_child_weight`: 1-20
  - `subsample`: 0.5-1.0
  - `colsample_bytree`: 0.5-1.0
  - `gamma`: 0-2
  - `reg_alpha`: 0-5 (L1 regularization)
  - `reg_lambda`: 0-10 (L2 regularization)

**Best Hyperparameters (Optuna-optimized):**
```python
{
    "n_estimators": 809,
    "learning_rate": 0.07799139066424228,
    "max_depth": 10,
    "min_child_weight": 4.061061163488145,
    "subsample": 0.5701048191854274,
    "colsample_bytree": 0.8581650610276089,
    "gamma": 0.00401540942931726,
    "reg_alpha": 0.77686055744257,
    "reg_lambda": 8.192269638825147,
    "tree_method": "hist",
    "n_jobs": -1,
    "random_state": 42
}
```

**Feature Engineering:**
- **Property Ratios:**
  - `sqft_per_bed`: House size per bedroom
  - `bed_bath_ratio`: Bedroom to bathroom ratio
  - `bed_bath_sum`: Total rooms
  - `house_to_lot_ratio`: Building footprint ratio

- **Temporal Features:**
  - `years_since_2000`: Time encoding
  - `is_recent`: Binary flag for properties sold after 2015
  - `month_sin` / `month_cos`: Cyclical month encoding
  - `decade`: Long-term trend capture

- **Location Aggregations:**
  - `zip_price_mean` / `zip_price_median`: ZIP-level price statistics
  - `zip_size_mean`: Average house size in ZIP
  - `zip_count`: Number of properties in ZIP
  - `city_size`: Number of properties in city
  - `is_large_city`: Binary flag for cities with 1000+ properties

- **Growth Features:**
  - `zip_growth_rate`: Historical year-over-year growth by ZIP code
  - Calculated from median prices grouped by ZIP and year

**Target Transformation:**
- Used **log1p transformation** (`log(1 + price)`) for:
  - Handling price skewness
  - Reducing impact of extreme values
  - Improving model convergence
  - Predictions transformed back using `expm1()`

**Clustering Configuration:**
- **Algorithm:** MiniBatchKMeans
- **Number of Clusters:** 30
- **Batch Size:** 1,000
- **Max Iterations:** 100
- **Initializations:** 3
- **Evaluation:** Silhouette score on 10,000 sample points

#### Tools, Libraries, and Frameworks

**Core Libraries:**
- `pandas`: Data manipulation and analysis
- `numpy`: Numerical computations
- `scikit-learn`: Machine learning utilities (train_test_split, metrics, preprocessing)
- `xgboost`: Gradient boosting framework
- `optuna`: Hyperparameter optimization
- `scipy`: Statistical functions (z-score, winsorize)

**Visualization:**
- `matplotlib`: Plotting and visualization
- `seaborn`: Statistical visualizations

**Utilities:**
- `pickle`: Model serialization
- `warnings`: Suppress warnings during execution

---

### 2.3 Implementation

#### System Design and Architecture

The project follows a modular pipeline architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA INGESTION                           â”‚
â”‚              (realtor-data.zip.csv)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA PREPROCESSING                         â”‚
â”‚  â€¢ Missing value imputation (hierarchical, ML-based)      â”‚
â”‚  â€¢ Outlier detection and treatment                          â”‚
â”‚  â€¢ Data type conversions                                    â”‚
â”‚  â€¢ Feature validation                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FEATURE ENGINEERING                        â”‚
â”‚  â€¢ Property ratios (sqft/bed, bed/bath, etc.)            â”‚
â”‚  â€¢ Temporal features (year, month, season)                  â”‚
â”‚  â€¢ Location aggregations (ZIP, city statistics)             â”‚
â”‚  â€¢ Growth rate calculations                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODEL TRAINING & OPTIMIZATION                  â”‚
â”‚  â€¢ Optuna hyperparameter tuning                             â”‚
â”‚  â€¢ XGBoost model training                                   â”‚
â”‚  â€¢ Model evaluation and validation                           â”‚
â”‚  â€¢ Model serialization                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PREDICTION & FORECASTING                       â”‚
â”‚  â€¢ Current price prediction                                 â”‚
â”‚  â€¢ 1, 5, 10-year forecasts                                 â”‚
â”‚  â€¢ ROI calculations                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           INVESTMENT RECOMMENDATION ENGINE                  â”‚
â”‚  â€¢ Property filtering (budget, location, features)          â”‚
â”‚  â€¢ Risk assessment (price volatility)                       â”‚
â”‚  â€¢ ROI ranking and recommendations                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GEOGRAPHIC CLUSTERING                          â”‚
â”‚  â€¢ Coordinate assignment (ZIP + jitter)                     â”‚
â”‚  â€¢ DBSCAN street-level clustering (50m radius)             â”‚
â”‚  â€¢ Alternative: MiniBatchKMeans (30 clusters)              â”‚
â”‚  â€¢ Cluster analysis and visualization                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Workflow

1. **Data Preparation Phase:**
   - Load raw CSV data
   - Initial data quality assessment
   - Missing value analysis

2. **Data Cleaning Phase:**
   - Remove invalid records
   - Apply imputation strategies (hierarchical â†’ ML-based)
   - Outlier detection and treatment
   - Data validation

3. **Feature Engineering Phase:**
   - Create derived features
   - Compute location-based aggregations
   - Generate temporal features
   - Calculate growth rates

4. **Model Development Phase:**
   - Train/validation/test split (80/10/10)
   - Hyperparameter optimization with Optuna
   - Model training with best parameters
   - Performance evaluation

5. **Forecasting Phase:**
   - Time-based feature adjustment
   - Multi-horizon predictions (1, 5, 10 years)
   - Growth rate integration
   - Inflation adjustment

6. **Investment Analysis Phase:**
   - Property filtering by criteria
   - ROI calculation for each property
   - Risk assessment
   - Ranking and recommendation

7. **Clustering Phase:**
   - Geographic coordinate assignment (ZIP centroids + jitter)
   - **DBSCAN Street-Level Clustering:**
     - Group properties by street name
     - Apply DBSCAN clustering within each street (50m radius)
     - Assign global cluster IDs
     - Identify noise points (isolated properties)
   - **Alternative: MiniBatchKMeans** for overall geographic clustering (30 clusters)
   - Cluster statistics and analysis
   - Spatial pattern identification

#### Programming Languages and Environments

- **Language:** Python 3.x
- **Environment:** Jupyter Notebook (Google Colab)
- **Key Python Packages:**
  - pandas 1.5+
  - numpy 1.23+
  - xgboost 2.0+
  - scikit-learn 1.2+
  - optuna 3.0+

#### System Components

1. **Data Cleaning Module:**
   - `smart_impute_bed_bath()`: Hierarchical imputation for bedrooms/bathrooms
   - `smart_fast_imputation()`: Fast acre lot imputation
   - `zip_price_pattern_imputation()`: Street address generation
   - `debugged_house_size_imputation()`: XGBoost-based house size prediction
   - `fixed_fast_ml_date_imputation()`: ML-based date imputation
   - `detect_and_treat_outliers_advanced()`: Comprehensive outlier treatment

2. **Modeling Module:**
   - `optimized_xgboost_optuna()`: Hyperparameter optimization
   - `xgboost_best_model()`: Final model training with best parameters
   - `train_time_forecasting_model()`: Time-based forecasting model

3. **Investment Module:**
   - `RealEstateInvestmentAdvisor` class: Main recommendation engine
   - `PropertyPriceForecaster` class: Time-based price forecasting
   - Methods: `recommend_investments()`, `forecast_price()`, `compute_risk()`
   
   **Detailed Workflow:**
   - **Input:** Budget, optional filters (state, city, bedrooms, bathrooms)
   - **Process:** Filters properties â†’ Forecasts prices â†’ Calculates ROI â†’ Assesses risk â†’ Ranks by ROI
   - **Output:** Top 10 investment opportunities with ROI metrics and risk scores

4. **Clustering Module:**
   - Coordinate assignment with ZIP centroids + jitter
   - **DBSCAN street-level clustering:** Clusters houses within each street by proximity (50m radius)
   - **MiniBatchKMeans clustering:** Alternative approach for overall geographic clustering (30 clusters)
   - Cluster analysis, statistics, and visualization
   - Output: `street_cluster` and `within_street_cluster` columns

---

### 2.4 Advanced Models: Forecasting and Investment Recommendation

#### Model 1: PropertyPriceForecaster (10-Year Price Forecasting)

**Overview:**
The PropertyPriceForecaster is a sophisticated time-based forecasting system that predicts property prices for 1, 5, and 10 years into the future. It combines machine learning predictions with historical market trends to provide robust, realistic forecasts.

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROPERTY INPUT DATA                            â”‚
â”‚  (house_size, bed, bath, acre_lot, zip_code, sold_year)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HISTORICAL GROWTH RATE CALCULATION                  â”‚
â”‚  â€¢ Calculate YoY median price changes by ZIP code          â”‚
â”‚  â€¢ Compute overall market growth rate                      â”‚
â”‚  â€¢ Store ZIP-specific growth rates                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CURRENT PRICE PREDICTION (XGBoost)                  â”‚
â”‚  â€¢ Engineer temporal features for current year              â”‚
â”‚  â€¢ Predict using trained XGBoost model                    â”‚
â”‚  â€¢ Transform from log space to actual price                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FUTURE PRICE PREDICTIONS (1, 5, 10 years)           â”‚
â”‚                                                              â”‚
â”‚  For each horizon (1yr, 5yr, 10yr):                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 1. ML Prediction:                            â”‚            â”‚
â”‚  â”‚    â€¢ Adjust temporal features for target    â”‚            â”‚
â”‚  â”‚      year (years_since_2000, decade, etc.)  â”‚            â”‚
â”‚  â”‚    â€¢ Predict using XGBoost model           â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 2. Trend Prediction:                       â”‚            â”‚
â”‚  â”‚    â€¢ Get ZIP-specific growth rate          â”‚            â”‚
â”‚  â”‚    â€¢ Add inflation (2.5% annually)        â”‚            â”‚
â”‚  â”‚    â€¢ Apply compound growth:                 â”‚            â”‚
â”‚  â”‚      Price_t = Price_0 Ã— (1 + rate)^t     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 3. Blending (70% ML + 30% Trend):          â”‚            â”‚
â”‚  â”‚    Final = 0.7 Ã— ML_pred + 0.3 Ã— Trend_predâ”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OUTPUT: PRICE FORECASTS                         â”‚
â”‚  â€¢ Current price                                            â”‚
â”‚  â€¢ 1-year forecast with percentage change                    â”‚
â”‚  â€¢ 5-year forecast with percentage change                    â”‚
â”‚  â€¢ 10-year forecast with percentage change                   â”‚
â”‚  â€¢ Growth rate used                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features:**
- **ZIP-Specific Growth Rates:** Each ZIP code has its own historical growth rate calculated from past sales data
- **Inflation Adjustment:** Adds 2.5% annual inflation to growth rates for realistic projections
- **Growth Rate Bounds:** Caps growth rates between 2% and 8% annually to prevent unrealistic forecasts
- **Hybrid Approach:** Blends ML predictions (captures complex patterns) with trend-based forecasts (captures market momentum)
- **Temporal Feature Engineering:** Adjusts time-based features (years_since_2000, decade, is_recent) for each forecast horizon

**Example Usage:**
```python
forecaster = PropertyPriceForecaster("model_predict_10_years.pkl")

property_info = {
    "house_size": 2200,
    "bed": 3,
    "bath": 2,
    "acre_lot": 0.5,
    "zip_code": 92057,
    "sold_year": 2024
}

results = forecaster.predict_prices(property_info)
# Returns: current_price, price_1_year, price_5_year, price_10_year, growth_rate_used
```

**Performance:**
- **RÂ² Score:** 0.8393 (same as base model, as it uses the same XGBoost model)
- **Forecast Accuracy:** Validated against historical data with growth rate adjustments
- **Processing Time:** <10ms per property forecast

---

#### Model 2: RealEstateInvestmentAdvisor (ROI-Based Investment Recommendations)

**Overview:**
The RealEstateInvestmentAdvisor is a comprehensive investment analysis system that identifies the best property investment opportunities based on user-specified budget and criteria. It evaluates properties by forecasting future prices, calculating ROI, and assessing risk to provide ranked recommendations.

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT                                â”‚
â”‚  â€¢ Budget (maximum investment amount)                        â”‚
â”‚  â€¢ Optional: State, City, Min/Max Beds, Min Baths           â”‚
â”‚  â€¢ Top N (number of recommendations, default: 10)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROPERTY FILTERING PHASE                        â”‚
â”‚                                                              â”‚
â”‚  1. Load all properties from cleaned dataset                 â”‚
â”‚  2. Apply location filters (state, city)                   â”‚
â”‚  3. Apply feature filters (bedrooms, bathrooms)            â”‚
â”‚  4. Filter by budget (price â‰¤ budget)                       â”‚
â”‚  5. Sample up to 5,000 properties (performance optimization) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FOR EACH PROPERTY: ANALYSIS LOOP                     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Step 1: Price Forecasting                  â”‚            â”‚
â”‚  â”‚  â€¢ Forecast price at 1 year                 â”‚            â”‚
â”‚  â”‚  â€¢ Forecast price at 5 years               â”‚            â”‚
â”‚  â”‚  â€¢ Forecast price at 10 years               â”‚            â”‚
â”‚  â”‚  (Uses PropertyPriceForecaster model)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Step 2: ROI Calculation                    â”‚            â”‚
â”‚  â”‚  â€¢ ROI_1yr = (Price_1yr - Current) /       â”‚            â”‚
â”‚  â”‚              Current Ã— 100                  â”‚            â”‚
â”‚  â”‚  â€¢ ROI_5yr = (Price_5yr - Current) /       â”‚            â”‚
â”‚  â”‚              Current Ã— 100                  â”‚            â”‚
â”‚  â”‚  â€¢ ROI_10yr = (Price_10yr - Current) /      â”‚            â”‚
â”‚  â”‚               Current Ã— 100                 â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Step 3: Risk Assessment                    â”‚            â”‚
â”‚  â”‚  â€¢ Get all prices in same ZIP code          â”‚            â”‚
â”‚  â”‚  â€¢ Calculate coefficient of variation:      â”‚            â”‚
â”‚  â”‚    Risk = std(price) / mean(price)          â”‚            â”‚
â”‚  â”‚  â€¢ Higher risk = more price volatility      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Step 4: Risk-Adjusted ROI                  â”‚            â”‚
â”‚  â”‚  â€¢ risk_adjusted_roi = ROI_10yr / (1+risk) â”‚            â”‚
â”‚  â”‚  â€¢ Penalizes high-risk investments          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RANKING AND SELECTION                           â”‚
â”‚                                                              â”‚
â”‚  1. Sort all properties by ROI_10yr (descending)            â”‚
â”‚  2. Select top N properties (default: 10)                  â”‚
â”‚  3. Include all metrics for each recommendation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OUTPUT: RECOMMENDATION RESULTS                  â”‚
â”‚                                                              â”‚
â”‚  Returns dictionary with:                                   â”‚
â”‚  â€¢ success: Boolean status                                  â”‚
â”‚  â€¢ data: List of top N properties with:                    â”‚
â”‚    - Location (state, city, zip_code)                       â”‚
â”‚    - Property features (beds, baths, house_size)           â”‚
â”‚    - Current price                                          â”‚
â”‚    - Forecasted prices (1yr, 5yr, 10yr)                    â”‚
â”‚    - ROI metrics (1yr, 5yr, 10yr)                           â”‚
â”‚    - Risk score                                             â”‚
â”‚    - Risk-adjusted ROI                                       â”‚
â”‚  â€¢ message: Status message                                 â”‚
â”‚  â€¢ total_analyzed: Number of properties evaluated          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features:**
- **Flexible Filtering:** Supports multiple filter criteria (budget, location, property features)
- **Multi-Horizon ROI:** Calculates ROI for 1, 5, and 10-year investment horizons
- **Risk Quantification:** Measures price volatility at ZIP code level using coefficient of variation
- **Risk-Adjusted Returns:** Provides risk-adjusted ROI metric to balance returns with risk
- **Scalable Processing:** Handles large datasets efficiently with sampling for performance
- **Production-Ready:** Flask-compatible with proper error handling and JSON responses

**ROI Calculation Formula:**
```
ROI_t = (Price_t - Price_current) / Price_current Ã— 100%

Where:
  Price_current = Current property price
  Price_t = Forecasted price at time t (1, 5, or 10 years)
  ROI_t = Return on Investment at time t (percentage)
```

**Risk Assessment Formula:**
```
Risk = Ïƒ(price) / Î¼(price)

Where:
  Ïƒ(price) = Standard deviation of prices in ZIP code
  Î¼(price) = Mean price in ZIP code
  Risk = Coefficient of variation (0.0 = no risk, higher = more volatile)
```

**Risk-Adjusted ROI:**
```
risk_adjusted_roi = ROI_10yr / (1 + Risk)

This metric penalizes high-risk investments, providing a more conservative
estimate of returns that accounts for price volatility.
```

**Example Usage:**
```python
advisor = RealEstateInvestmentAdvisor("model_best.pkl", "cleaned_data.csv")

results = advisor.recommend_investments(
    budget=500000,
    state="California",
    min_beds=3,
    top_n=10,
    verbose=False
)

# Returns top 10 properties with highest 10-year ROI
# Each property includes: location, features, prices, ROI metrics, risk
```

**Output Example:**
```json
{
  "success": true,
  "data": [
    {
      "state": "California",
      "city": "Los Angeles",
      "zip_code": 90001,
      "beds": 3,
      "baths": 2,
      "house_size": 2200,
      "current_price": 450000,
      "price_1yr": 465000,
      "price_5yr": 520000,
      "price_10yr": 600000,
      "roi_1_year": 3.33,
      "roi_5_year": 15.56,
      "roi_10_year": 33.33,
      "risk": 0.15,
      "risk_adjusted_roi": 28.98
    },
    ...
  ],
  "message": "Found 500 investment opportunities",
  "total_analyzed": 500
}
```

**Performance:**
- **Processing Speed:** ~2-3 seconds for 1,000 properties
- **Scalability:** Handles up to 5,000 properties per query (sampled if more)
- **Accuracy:** Uses same high-performance XGBoost model (RÂ² = 0.8392)
- **Memory Usage:** ~2-4 GB for full dataset analysis

**Integration:**
- **Flask API Ready:** Can be deployed as REST API endpoint
- **Web Application:** Includes HTML interface for user interaction
- **Batch Processing:** Supports analyzing multiple properties simultaneously

---

## 3. Experiments & Results

### 3.1 Experiments Conducted

#### Experiment 1: Hyperparameter Optimization
- **Method:** Optuna framework with 30 trials
- **Sample Size:** 300,000 properties (for tuning speed)
- **Validation Split:** 20% of tuning sample
- **Objective:** Minimize Mean Squared Error (MSE) on validation set
- **Result:** Identified optimal hyperparameters (see Section 2.2)

#### Experiment 2: Model Training and Evaluation
- **Dataset Split:**
  - Training: 80% (1,779,649 properties)
  - Test: 20% (444,912 properties)
- **Training Time:** ~5-10 minutes (depending on hardware)
- **Evaluation Metrics:** RÂ², MAE, RMSE, MAPE

#### Experiment 3: Time-Based Forecasting
- **Approach:** Extended model with temporal features and growth rates
- **Forecast Horizons:** 1, 5, and 10 years
- **Growth Rate Calculation:** Year-over-year median price changes by ZIP code
- **Inflation Adjustment:** 2.5% annual inflation rate

#### Experiment 4: Time-Based Forecasting Model
- **Approach:** Extended base XGBoost model with temporal features and growth rate integration
- **Growth Rate Calculation:** Analyzed year-over-year price changes by ZIP code from historical data
- **Blending Strategy:** Tested different weights (50/50, 60/40, 70/30, 80/20) for ML vs trend predictions
- **Final Configuration:** 70% ML prediction + 30% trend-based growth (best balance of accuracy and realism)
- **Inflation Adjustment:** Applied 2.5% annual inflation rate based on historical averages
- **Growth Rate Bounds:** Tested various bounds; settled on 2-8% annually to prevent unrealistic forecasts

#### Experiment 5: Investment Recommendation System
- **Filtering Efficiency:** Tested different sampling strategies for large datasets
- **ROI Calculation:** Validated ROI formulas against known investment outcomes
- **Risk Assessment:** Compared coefficient of variation vs other risk metrics (variance, range)
- **Ranking Strategy:** Tested ranking by ROI_10yr vs risk-adjusted ROI vs weighted combinations
- **Final Approach:** Rank by ROI_10yr (primary), include risk-adjusted ROI (secondary metric)
- **Performance Optimization:** Limited analysis to 5,000 properties per query for response time

#### Experiment 6: Street-Level Geographic Clustering

This experiment aimed to identify spatial patterns and group properties into geographic clusters based on their locations, specifically focusing on clustering houses within the same street. The goal was to create location-based features that could improve price predictions by capturing neighborhood-level market characteristics. Since street addresses were not geocoded, we assigned coordinates using ZIP code centroids with small random jitter to differentiate properties within the same ZIP code. We tested multiple clustering approaches to find the most effective solution for our large dataset of 2.2+ million properties.

**Initial Attempts:**
- **KMeans vs HDBSCAN:** Tested both algorithms on full dataset, but both were too slow (>1.5 hours) or failed to produce meaningful results
- **KMeans:** Required pre-specifying number of clusters, struggled with irregular geographic patterns
- **HDBSCAN:** Too computationally expensive for 2.2M+ points, took over 1.5 hours

**Final Implementation - DBSCAN Street-Level Clustering:**
- **Algorithm:** DBSCAN (Density-Based Spatial Clustering)
- **Strategy:** Cluster houses within each street separately, then assign global cluster IDs
- **Parameters:**
  - **Radius (eps):** 50 meters - houses within this distance are grouped together
  - **Min Samples:** 2 houses minimum to form a cluster
  - **Metric:** Euclidean distance in coordinate space
- **Process:**
  1. Group properties by street name
  2. For each street, apply DBSCAN clustering based on geographic proximity
  3. Assign unique global cluster IDs across all streets
  4. Identify noise points (isolated properties that don't form clusters)
- **Performance:** Completed in seconds (much faster than KMeans/HDBSCAN on full dataset)
- **Output:** Two cluster columns:
  - `street_cluster`: Global cluster ID (unique across all streets)
  - `within_street_cluster`: Local cluster ID within each street

**Alternative Approach - MiniBatchKMeans:**
- **Purpose:** Fast alternative for overall geographic clustering (not street-specific)
- **Configuration:** 30 clusters, batch processing for efficiency
- **Performance:** 0.30 seconds training time
- **Evaluation:** Silhouette score of 0.4768 on 10,000 sample points

### 3.2 Metrics and Results

#### Model Performance Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **RÂ² Score** | 0.8392 | Model explains 83.92% of price variance |
| **MAE** | $101,759 | Average prediction error |
| **RMSE** | $274,206 | Standard deviation of prediction errors |
| **MAPE** | 25.46% | Mean absolute percentage error |

#### Feature Importance (Top 15)

| Rank | Feature | Importance | Description |
|------|---------|------------|-------------|
| 1 | `house_size` | 0.439 | House square footage |
| 2 | `zip_price_median` | 0.149 | Median price in ZIP code |
| 3 | `zip_price_mean` | 0.096 | Mean price in ZIP code |
| 4 | `bath` | 0.082 | Number of bathrooms |
| 5 | `sqft_per_bed` | 0.062 | Square feet per bedroom |
| 6 | `bed_bath_sum` | 0.046 | Total rooms (bed + bath) |
| 7 | `zip_size_mean` | 0.017 | Average house size in ZIP |
| 8 | `lot_size_sqft` | 0.015 | Lot size in square feet |
| 9 | `bed_bath_ratio` | 0.012 | Bedroom to bathroom ratio |
| 10 | `bed` | 0.012 | Number of bedrooms |
| 11 | `acre_lot` | 0.012 | Lot size in acres |
| 12 | `zip_code` | 0.010 | ZIP code (categorical) |
| 13 | `is_recent` | 0.009 | Recent sale flag |
| 14 | `house_to_lot_ratio` | 0.009 | Building footprint ratio |
| 15 | `years_since_2000` | 0.008 | Temporal encoding |

**Key Insights:**
- House size is the most important feature (43.9% importance)
- Location features (ZIP-level statistics) are highly predictive (24.5% combined)
- Property characteristics (bath, bed, ratios) contribute significantly
- Temporal features have moderate importance

#### Clustering Results

**DBSCAN Street-Level Clustering:**

| Metric | Value |
|--------|-------|
| **Clustering Algorithm** | DBSCAN (Density-Based) |
| **Clustering Radius** | 50 meters |
| **Min Samples per Cluster** | 2 houses |
| **Total Properties Processed** | 2,223,412 |
| **Unique Streets Analyzed** | Varies by dataset |
| **Processing Time** | Seconds (highly efficient) |
| **Clustered Properties** | Varies (percentage depends on street density) |
| **Noise Points (Isolated)** | Properties that don't form clusters |

**Key Features:**
- **Street-Specific Clustering:** Each street is clustered independently, then assigned global IDs
- **Geographic Granularity:** 50-meter radius captures nearby houses on same street
- **Automatic Cluster Detection:** No need to pre-specify number of clusters
- **Noise Handling:** Identifies isolated properties that don't belong to any cluster
- **Two-Level Clustering:**
  - `street_cluster`: Global cluster ID across all streets
  - `within_street_cluster`: Local cluster ID within each street

**Cluster Characteristics:**
- Clusters represent groups of nearby houses on the same street
- Average cluster diameter: ~50 meters (based on eps parameter)
- Cluster sizes vary based on street density and property distribution
- Suitable for analyzing price variations within street segments

**Alternative: MiniBatchKMeans Results (Overall Geographic Clustering):**

| Metric | Value |
|--------|-------|
| **Number of Clusters** | 30 |
| **Silhouette Score** | 0.4768 |
| **Training Time** | 0.30 seconds |
| **Total Properties Clustered** | 2,223,412 |
| **Average Properties per Cluster** | 74,114 |
| **Largest Cluster** | 179,081 properties |
| **Smallest Cluster** | 489 properties |

**Cluster Distribution:**
- Well-balanced clusters with reasonable size distribution
- Geographic spread: clusters cover 5-17Â° latitude/longitude ranges
- Suitable for location-based feature engineering at regional level

#### Forecasting Model Performance

**Model Architecture:**
- **Base Model:** XGBoost with RÂ² = 0.8393
- **Growth Rate Coverage:** Calculated for all ZIP codes with sufficient historical data
- **Blending Weight:** 70% ML prediction, 30% trend-based growth
- **Inflation Rate:** 2.5% annually

**Forecasting Performance Example:**

**Sample Property 1:**
- **Property:** 5,000 sqft, 3 bed, 2 bath, 1000 acres, ZIP 601
- **Current Year:** 2024
- **Current Price:** $1,003,368
- **1-Year Forecast:** $1,027,448 (+2.4%)
- **5-Year Forecast:** $1,144,640 (+14.1%)
- **10-Year Forecast:** $1,352,216 (+34.8%)
- **Growth Rate Used:** 8.00% annually (ZIP-specific)

**Sample Property 2:**
- **Property:** 2,200 sqft, 3 bed, 2 bath, 0.5 acres, ZIP 92057
- **Current Year:** 2024
- **Current Price:** $557,462
- **1-Year Forecast:** $570,000 (+2.2%)
- **5-Year Forecast:** $625,000 (+12.1%)
- **10-Year Forecast:** $720,000 (+29.1%)
- **Growth Rate Used:** 5.50% annually (ZIP-specific)

**Key Insights:**
- Growth rates vary significantly by location (2-8% range)
- Higher-value properties tend to have higher growth rates
- Model captures location-specific market trends effectively
- Blending approach provides more stable forecasts than pure ML or pure trend

#### Investment Recommendation System Performance

**System Capabilities:**
- **Properties Analyzed:** Up to 5,000 per query (sampled from larger datasets)
- **Processing Time:** ~2-3 seconds for 1,000 properties
- **ROI Calculation:** Multi-horizon (1, 5, 10 years)
- **Risk Assessment:** ZIP code-level volatility analysis

**Example Recommendation Output:**

**Query:** Budget = $500,000, State = California, Min Beds = 3, Top 10

**Top 3 Recommendations:**

| Rank | Location | Beds/Baths | Current Price | 10-Yr ROI | Risk | Risk-Adj ROI |
|------|----------|------------|---------------|-----------|------|--------------|
| 1 | Los Angeles, CA | 3/2 | $450,000 | 33.33% | 0.15 | 28.98% |
| 2 | San Diego, CA | 3/2.5 | $480,000 | 31.25% | 0.12 | 27.90% |
| 3 | Sacramento, CA | 4/2 | $420,000 | 28.57% | 0.18 | 24.21% |

**Detailed Metrics for Top Recommendation:**
- **Current Price:** $450,000
- **1-Year Forecast:** $465,000 (ROI: 3.33%)
- **5-Year Forecast:** $520,000 (ROI: 15.56%)
- **10-Year Forecast:** $600,000 (ROI: 33.33%)
- **Risk Score:** 0.15 (15% price volatility in ZIP code)
- **Risk-Adjusted ROI:** 28.98% (accounts for volatility)
- **Property Features:** 2,200 sqft, 3 bed, 2 bath, 0.5 acres

**System Performance Metrics:**
- **Average Processing Time:** 2.5 seconds per 1,000 properties
- **ROI Range:** Typically 15-40% for 10-year horizon
- **Risk Range:** 0.10-0.30 (10-30% price volatility)
- **Success Rate:** 95%+ queries return valid recommendations
- **Scalability:** Handles datasets with 100K+ properties efficiently

### 3.3 Comparison with Baseline

**Baseline Approach (Simple Linear Regression):**
- **RÂ² Score:** ~0.65-0.70 (estimated)
- **MAE:** ~$150,000-200,000 (estimated)
- **Limitations:** Cannot capture non-linear relationships, location interactions

**Our XGBoost Model:**
- **RÂ² Score:** 0.8392 (+19-24% improvement)
- **MAE:** $101,759 (33-49% reduction)
- **Advantages:**
  - Captures complex feature interactions
  - Handles non-linear relationships
  - Location-aware predictions
  - Temporal trend integration

---

## 4. Discussion & Challenges

### 4.1 Limitations and Challenges

#### Data Quality Challenges

1. **High Missing Value Rates:**
   - **Challenge:** 25.5% missing house sizes, 33% missing sale dates
   - **Solution:** Implemented sophisticated ML-based imputation (XGBoost for house size, temporal model for dates)
   - **Impact:** Imputation quality directly affects model performance

2. **Data Skewness:**
   - **Challenge:** Price distribution highly skewed (few luxury properties, many affordable)
   - **Solution:** Log transformation of target variable, percentile-based outlier capping
   - **Remaining Issue:** MAPE of 25.46% indicates room for improvement on extreme values

3. **Geographic Data Limitations:**
   - **Challenge:** Street addresses not geocoded, only ZIP-level coordinates
   - **Solution:** Assigned ZIP centroids with random jitter for clustering
   - **Limitation:** Clustering granularity limited by ZIP code resolution

#### Computational Challenges

1. **Large Dataset Size:**
   - **Challenge:** 2.2M+ properties require efficient processing
   - **Solution:** 
     - Used MiniBatchKMeans instead of standard KMeans (100x faster)
     - Implemented batch processing for predictions
     - Memory-efficient feature engineering
   - **Result:** Clustering completed in 0.30 seconds vs >1.5 hours

2. **Model Training Time:**
   - **Challenge:** Full dataset training with Optuna takes hours
   - **Solution:** Sampled 300K properties for hyperparameter tuning, then trained on full dataset
   - **Trade-off:** Slight suboptimality in hyperparameters for speed

3. **Memory Constraints:**
   - **Challenge:** Large feature matrices and model objects
   - **Solution:** 
     - Used float32 instead of float64 where possible
     - Batch processing for predictions
     - Garbage collection between steps
   - **Result:** Model file size: 376 MB (acceptable for deployment)

#### Model Limitations

1. **Temporal Forecasting Uncertainty:**
   - **Challenge:** Long-term forecasts (10 years) subject to market volatility
   - **Limitation:** Model assumes historical growth patterns continue
   - **Risk:** Economic shocks, policy changes not captured

2. **Location Feature Granularity:**
   - **Challenge:** ZIP-level aggregations may miss neighborhood-level variations
   - **Impact:** Predictions may be less accurate in heterogeneous ZIP codes
   - **Future Work:** Incorporate census tract or block-level data

3. **Feature Engineering Assumptions:**
   - **Challenge:** Some engineered features (e.g., growth rates) assume stationarity
   - **Limitation:** Market conditions may change, affecting feature validity
   - **Mitigation:** Regular model retraining with recent data

### 4.2 Unexpected Results and Handling

#### Unexpected Result 1: House Size Imputation Range
- **Issue:** Initial imputation produced unrealistic sizes (up to 1 billion sqft)
- **Root Cause:** Missing constraints in XGBoost predictions
- **Solution:** Added multi-level constraints:
  - Bedroom-based limits (300-800 sqft per bedroom)
  - Price per sqft validation ($50-$500)
  - Lot size constraints (house â‰¤ 60% of lot)
  - Final bounds (500-10,000 sqft)
- **Result:** Realistic size distribution with median 1,625 sqft

#### Unexpected Result 2: HDBSCAN Clustering Failure
- **Issue:** HDBSCAN clustering took >1.5 hours and produced poor results
- **Root Cause:** Algorithm complexity scales poorly with 2.2M points
- **Solution:** Switched to MiniBatchKMeans
- **Result:** 0.30 seconds training time, acceptable silhouette score (0.4768)

#### Unexpected Result 3: XGBoost Early Stopping Error
- **Issue:** `early_stopping_rounds` parameter not recognized in newer XGBoost version
- **Root Cause:** API change in XGBoost 2.0+
- **Solution:** Removed early stopping, used fixed number of estimators
- **Impact:** Slightly longer training time, but more stable

#### Unexpected Result 4: Date Imputation Future Dates
- **Issue:** ML model predicted dates in the future (after 2024)
- **Root Cause:** Model learned from historical data but didn't constrain predictions
- **Solution:** Added temporal constraints:
  - Cap future dates to 30 days before current date
  - Floor old dates to 1990-01-01
  - Add random variation for very old dates
- **Result:** All dates within valid range

### 4.3 Key Lessons Learned

1. **Data Quality is Paramount:**
   - Invest significant time in data cleaning and imputation
   - ML-based imputation outperforms simple statistical methods
   - Validation and constraint checking prevent unrealistic predictions

2. **Feature Engineering Impact:**
   - Location aggregations (ZIP-level statistics) are highly predictive
   - Temporal features capture market trends effectively
   - Ratios and derived features add significant value

3. **Algorithm Selection Matters:**
   - XGBoost excels on tabular data with mixed feature types
   - MiniBatchKMeans is essential for large-scale clustering
   - Consider computational efficiency, not just accuracy

4. **Hyperparameter Optimization:**
   - Optuna provides efficient search with minimal trials
   - Sampling for tuning speeds up process without major accuracy loss
   - Regularization (L1/L2) crucial for preventing overfitting

5. **Production Considerations:**
   - Model size (376 MB) acceptable but requires efficient loading
   - Batch processing necessary for large-scale predictions
   - Error handling and validation critical for deployment

6. **Forecasting Challenges:**
   - Long-term forecasts inherently uncertain
   - Growth rate assumptions may not hold in changing markets
   - Blend model predictions with trend-based adjustments

---

## 5. Conclusion & Future Work

### 5.1 Main Results Summary

This project successfully developed a comprehensive real estate price prediction and investment analysis system with the following achievements:

1. **High-Performance Prediction Model:**
   - Achieved **RÂ² score of 0.8392**, demonstrating strong predictive capability
   - **MAE of $101,759** provides practical accuracy for real estate investment decisions
   - Model successfully handles 2.2M+ properties with complex feature interactions

2. **Robust Data Processing Pipeline:**
   - Implemented sophisticated imputation strategies reducing missing values from 33% to 0%
   - Advanced outlier treatment preserving data distribution while removing anomalies
   - Comprehensive feature engineering creating 20+ predictive features

3. **Time-Based Forecasting:**
   - Successfully implemented 1, 5, and 10-year price forecasts
   - Integrated historical growth rates and inflation adjustments
   - Provides actionable insights for long-term investment planning

4. **Investment Recommendation System:**
   - Automated property filtering and ROI calculation
   - Risk assessment based on price volatility
   - Flask-ready deployment architecture

5. **Geographic Clustering:**
   - Efficient clustering of 2.2M+ properties in 0.30 seconds
   - Identified 30 spatial clusters for location-based analysis
   - Enables neighborhood-level market insights

### 5.2 Key Takeaways

1. **Machine Learning Excellence:**
   - XGBoost proves highly effective for real estate price prediction
   - Feature engineering, especially location aggregations, significantly improves performance
   - Hyperparameter optimization yields substantial gains

2. **Data Quality Foundation:**
   - Comprehensive data cleaning and imputation are essential
   - ML-based imputation outperforms traditional statistical methods
   - Constraint validation prevents unrealistic predictions

3. **Scalability Solutions:**
   - MiniBatchKMeans enables efficient large-scale clustering
   - Batch processing and memory optimization critical for production
   - Sampling strategies balance accuracy and computational cost

4. **Practical Applications:**
   - System provides actionable investment recommendations
   - Forecasting capabilities support long-term planning
   - Geographic clustering enables market segmentation

### 5.3 Future Work and Improvements

#### Short-Term Improvements (1-3 months)

1. **Enhanced Feature Engineering:**
   - Incorporate census data (income, demographics, education)
   - Add school district ratings and crime statistics
   - Include proximity features (distance to schools, parks, transit)
   - Weather and climate data for location desirability

2. **Model Improvements:**
   - Experiment with ensemble methods (XGBoost + LightGBM + CatBoost)
   - Implement neural networks for complex pattern recognition
   - Add uncertainty quantification (prediction intervals)
   - Cross-validation for more robust performance estimates

3. **Data Quality Enhancements:**
   - Integrate real-time data sources (Zillow API, Redfin API)
   - Add property images for computer vision features
   - Incorporate market sentiment from news/social media
   - Historical price trends at property level

#### Medium-Term Enhancements (3-6 months)

4. **Advanced Forecasting:**
   - Implement time series models (ARIMA, Prophet) for temporal trends
   - Add economic indicators (interest rates, GDP, unemployment)
   - Scenario analysis (optimistic, baseline, pessimistic forecasts)
   - Monte Carlo simulation for uncertainty quantification

5. **Geographic Improvements:**
   - Integrate precise geocoding (latitude/longitude for each property)
   - Implement spatial regression models (Geographically Weighted Regression)
   - Add neighborhood boundaries and characteristics
   - Heat maps and interactive visualizations

6. **Investment Analysis Enhancements:**
   - Rental yield estimation for investment properties
   - Tax implications and deductions calculator
   - Financing options and mortgage rate integration
   - Portfolio optimization for multiple properties

#### Long-Term Vision (6-12 months)

7. **Real-Time System:**
   - Live data pipeline with streaming updates
   - Real-time model retraining and deployment
   - Automated alert system for investment opportunities
   - Mobile application for on-the-go access

8. **Advanced Analytics:**
   - Market trend analysis and anomaly detection
   - Comparative market analysis (CMA) automation
   - Price prediction confidence intervals
   - Risk-adjusted return optimization

9. **Integration and Deployment:**
   - RESTful API for third-party integrations
   - Web dashboard with interactive visualizations
   - Integration with real estate platforms (MLS, Zillow)
   - Cloud deployment (AWS, GCP, Azure)

10. **Research Directions:**
    - Causal inference for understanding price drivers
    - Fairness and bias analysis across demographics
    - Explainable AI for model interpretability
    - Multi-task learning (price + time-on-market + rental yield)

#### Technical Debt and Maintenance

- **Model Monitoring:** Implement drift detection and performance tracking
- **A/B Testing:** Compare model versions in production
- **Documentation:** Comprehensive API documentation and user guides
- **Testing:** Unit tests, integration tests, and validation pipelines
- **Version Control:** Model versioning and rollback capabilities

---

## Appendix: Technical Details

### A. Data Schema

**Original Columns:**
- `brokered_by`: Real estate broker/company
- `status`: Property status (for_sale, sold, ready_to_build)
- `price`: Property price (USD)
- `bed`: Number of bedrooms
- `bath`: Number of bathrooms
- `acre_lot`: Lot size in acres
- `street`: Street address
- `city`: City name
- `state`: State abbreviation
- `zip_code`: ZIP code
- `house_size`: House size in square feet
- `prev_sold_date`: Previous sale date

### B. Model Architecture

**XGBoost Configuration:**
- Tree method: `hist` (histogram-based, memory efficient)
- Objective: `reg:squarederror`
- Evaluation metric: MSE
- Early stopping: Disabled (fixed n_estimators)
- Parallel processing: `n_jobs=-1` (all CPU cores)

### C. Performance Benchmarks

**Training Time:**
- Hyperparameter optimization: ~30-60 minutes (30 trials)
- Final model training: ~5-10 minutes
- Clustering: 0.30 seconds

**Prediction Speed:**
- Single property: <10ms
- Batch (10,000 properties): ~2-3 seconds
- Full dataset (2.2M): ~10-15 minutes

**Memory Usage:**
- Model file: 376 MB
- Training memory: ~8-12 GB
- Inference memory: ~2-4 GB

### D. Reproducibility

**Random Seeds:**
- Data sampling: `random_state=42`
- Train/test split: `random_state=42`
- XGBoost: `random_state=42`
- Clustering: `random_state=42`

**Environment:**
- Python 3.x
- Jupyter Notebook / Google Colab
- All dependencies listed in requirements (if provided)

---

## Contact and Acknowledgments

**Project:** Real Estate Price Prediction and Investment Recommendation System  
**Framework:** XGBoost, scikit-learn, Optuna  
**Dataset:** Realtor.com property data  
**Date:** 2024  
**Repository:** [Real-World-Asset-Tokenization-AI](https://github.com/aymendhieb02/Real-World-Asset-Tokenization-AI)  
**Branch:** `Models_AI`

For questions or contributions, please refer to the project repository or contact the development team.

---

## ðŸš€ Quick Start for Repository Setup

To push this code to the repository:

### Option 1: Using Setup Script (Recommended)

**Windows:**
```bash
.git_push_setup.bat
```

**Linux/Mac:**
```bash
chmod +x .git_push_setup.sh
./git_push_setup.sh
```

### Option 2: Manual Setup

```bash
# Initialize git (if not already)
git init

# Add remote repository
git remote add origin https://github.com/aymendhieb02/Real-World-Asset-Tokenization-AI.git

# Create and checkout Models_AI branch
git checkout -b Models_AI

# Add files
git add .

# Commit
git commit -m "Add AI models: Real Estate Price Prediction and Investment Recommendation System"

# Push to remote
git push -u origin Models_AI
```

### Important Notes

- **Large Files:** Model files (.pkl) and data files (.csv) are large. Consider using [Git LFS](https://git-lfs.github.com/):
  ```bash
  git lfs install
  git lfs track "*.pkl"
  git lfs track "*.csv"
  git add .gitattributes
  ```

- **Sensitive Data:** Ensure no sensitive data is committed. Check `.gitignore` before pushing.

- **Documentation:** See `MODELS_README.md` for quick reference and `DEPLOYMENT.md` for deployment guide.

---


